# Batch Gradient Descent for softmax regression

Batch Gradient Descent for softmax regression with L2 regularization and early stopping is implemented here from scratch. This model's code is then turned into scikit-learn transformer class in order to use it in a typical sklearn's fashion.